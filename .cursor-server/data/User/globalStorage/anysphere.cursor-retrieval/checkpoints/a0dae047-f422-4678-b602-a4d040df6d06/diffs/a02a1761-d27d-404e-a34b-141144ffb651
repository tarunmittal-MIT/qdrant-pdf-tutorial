{"fsPath":"\\home\\tarun\\qdrant_pdf_tutorial.py","fileUuid":"a02a1761-d27d-404e-a34b-141144ffb651","fileSizeBytes":23936,"numLines":690,"diffChanges":[{"originalStartLineNumberOneIndexed":1,"originalEndLineNumberExclusiveOneIndexed":1,"modifiedStartLineNumberOneIndexed":1,"modifiedEndLineNumberExclusiveOneIndexed":691,"addedLines":["\"\"\"","============================================================================","LESSON: Data Splitting and Chunking with Qdrant Vector Database","Using Azure AZ-104 Learning PDF","============================================================================","","Today's Agenda:","1. Download and extract text from Azure AZ-104 PDF","2. Data splitting strategies","3. Advanced chunking techniques for PDFs","4. Storing chunks in Qdrant vector database","5. Querying and retrieving relevant information","","Let's begin!","============================================================================","\"\"\"","","import os","import re","import uuid","from pathlib import Path","","# ============================================================================","# PART 1: SETUP AND DEPENDENCIES","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 1: SETUP AND INSTALLATION\")","print(\"=\"*70)","","print(\"\"\"","Required packages:","  pip install qdrant-client pymupdf sentence-transformers requests tqdm","","Note: Qdrant can run in two modes:","  1. Local mode (using QdrantClient in-memory or local storage)","  2. Cloud mode (using Qdrant Cloud or Docker container)","","For this tutorial, we'll use QdrantClient in local mode.","\"\"\")","","# ============================================================================","# PART 2: DOWNLOAD AZ-104 PDF","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 2: DOWNLOADING AZURE AZ-104 LEARNING PDF\")","print(\"=\"*70)","","def download_az104_pdf(pdf_path=\"az104-learning-guide.pdf\"):","    \"\"\"","    Download Azure AZ-104 learning PDF from Microsoft website.","    ","    Note: You may need to manually download from:","    https://learn.microsoft.com/en-us/credentials/certifications/exams/az-104/","    or search for \"AZ-104 study guide PDF\" on Microsoft Learn","    \"\"\"","    import requests","    ","    # Common URLs where the PDF might be available","    # Note: These are example URLs - actual download may require authentication","    possible_urls = [","        \"https://aka.ms/AZ-104StudyGuide\",  # Common Microsoft Learn shortcut","        \"https://learn.microsoft.com/en-us/training/paths/azure-administrator\",","    ]","    ","    if os.path.exists(pdf_path):","        print(f\"âœ“ PDF already exists at: {pdf_path}\")","        return pdf_path","    ","    print(\"\\nâš  PDF not found. Please download manually:\")","    print(\"   1. Visit: https://learn.microsoft.com/en-us/credentials/certifications/exams/az-104/\")","    print(\"   2. Look for study guide or exam preparation materials\")","    print(\"   3. Download the PDF and save it as 'az104-learning-guide.pdf'\")","    print(f\"   4. Or place it in the current directory: {os.getcwd()}\")","    ","    return None","","# Check for PDF","pdf_path = download_az104_pdf()","","# ============================================================================","# PART 3: PDF TEXT EXTRACTION","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 3: EXTRACTING TEXT FROM PDF\")","print(\"=\"*70)","","def extract_text_from_pdf(pdf_path):","    \"\"\"","    Extract text from PDF using PyMuPDF (fitz).","    ","    Args:","        pdf_path: Path to the PDF file","        ","    Returns:","        Dictionary with text, page info, and metadata","    \"\"\"","    try:","        import fitz  # PyMuPDF","        ","        if not os.path.exists(pdf_path):","            print(f\"âš  PDF not found: {pdf_path}\")","            print(\"Using sample text for demonstration...\")","            return {","                'full_text': \"\"\"","                Azure Administrator (AZ-104) Certification Guide","                ","                Module 1: Manage Azure Identities and Governance","                Azure Active Directory (Azure AD) is Microsoft's cloud-based identity and ","                access management service. It helps organizations manage users, groups, and ","                applications. Key features include single sign-on, multi-factor authentication, ","                and conditional access policies.","                ","                Module 2: Implement and Manage Storage","                Azure Storage provides scalable cloud storage for data objects. It includes ","                Blob Storage for unstructured data, File Storage for file shares, Queue Storage ","                for messaging, and Table Storage for NoSQL data. Storage accounts can be ","                configured with different performance tiers and redundancy options.","                ","                Module 3: Deploy and Manage Azure Compute Resources","                Azure Virtual Machines (VMs) provide on-demand, scalable computing resources. ","                Virtual Machine Scale Sets allow you to create and manage a group of load-balanced ","                VMs. Azure Container Instances offer serverless container execution, while ","                Azure Kubernetes Service (AKS) provides managed Kubernetes orchestration.","                ","                Module 4: Implement and Manage Virtual Networking","                Azure Virtual Network (VNet) enables Azure resources to communicate with each ","                other, the internet, and on-premises networks. Key components include subnets, ","                Network Security Groups (NSGs), VPN Gateways, and ExpressRoute for dedicated ","                connectivity.","                \"\"\",","                'pages': [{'page_num': 1, 'text': 'Sample text...'}],","                'total_pages': 1","            }","        ","        doc = fitz.open(pdf_path)","        full_text = \"\"","        pages_data = []","        ","        print(f\"\\n--- Processing PDF: {pdf_path} ---\")","        print(f\"Total pages: {len(doc)}\")","        ","        for page_num, page in enumerate(doc, 1):","            text = page.get_text()","            full_text += text + \"\\n\\n\"","            pages_data.append({","                'page_num': page_num,","                'text': text,","                'char_count': len(text)","            })","            ","            if page_num % 10 == 0:","                print(f\"  Processed {page_num}/{len(doc)} pages...\")","        ","        doc.close()","        ","        print(f\"âœ“ Extracted {len(full_text)} characters from {len(pages_data)} pages\")","        ","        return {","            'full_text': full_text,","            'pages': pages_data,","            'total_pages': len(pages_data)","        }","        ","    except ImportError:","        print(\"âš  PyMuPDF not installed. Install with: pip install pymupdf\")","        return None","    except Exception as e:","        print(f\"âš  Error extracting PDF: {e}\")","        return None","","# Extract text from PDF (or use sample if not available)","pdf_data = extract_text_from_pdf(pdf_path if pdf_path else \"az104-learning-guide.pdf\")","","if pdf_data:","    print(f\"\\nSample text (first 200 chars):\")","    print(pdf_data['full_text'][:200] + \"...\")","","# ============================================================================","# PART 4: DATA SPLITTING STRATEGIES","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 4: DATA SPLITTING STRATEGIES\")","print(\"=\"*70)","","def split_data_for_vector_db(text, split_ratio=0.8):","    \"\"\"","    Split data into indexing set and query/validation set.","    ","    Args:","        text: Full text content","        split_ratio: Ratio of data for indexing (rest for queries)","        ","    Returns:","        Tuple of (indexing_text, query_text)","    \"\"\"","    from sklearn.model_selection import train_test_split","    ","    # Split by paragraphs or sections","    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]","    ","    indexing_paragraphs, query_paragraphs = train_test_split(","        paragraphs,","        test_size=1 - split_ratio,","        random_state=42","    )","    ","    indexing_text = '\\n\\n'.join(indexing_paragraphs)","    query_text = '\\n\\n'.join(query_paragraphs)","    ","    return indexing_text, query_text","","if pdf_data:","    indexing_text, query_text = split_data_for_vector_db(pdf_data['full_text'])","    print(f\"\\nIndexing set: {len(indexing_text)} characters\")","    print(f\"Query set: {len(query_text)} characters\")","    print(f\"Split ratio: {len(indexing_text)/(len(indexing_text)+len(query_text))*100:.1f}%\")","","# ============================================================================","# PART 5: ADVANCED CHUNKING STRATEGIES","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 5: CHUNKING STRATEGIES FOR PDF DOCUMENTS\")","print(\"=\"*70)","","def sentence_chunk_text(text, sentences_per_chunk=3, chunk_overlap_sentences=1):","    \"\"\"","    Split text into chunks by sentences with overlap.","    Best for natural language documents like PDFs.","    ","    Args:","        text: Input text","        sentences_per_chunk: Number of sentences per chunk","        chunk_overlap_sentences: Number of overlapping sentences","        ","    Returns:","        List of text chunks","    \"\"\"","    # Split by sentences (handles multiple sentence endings)","    sentences = re.split(r'(?<=[.!?])\\s+', text)","    sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]","    ","    chunks = []","    i = 0","    while i < len(sentences):","        chunk_sentences = sentences[i:i+sentences_per_chunk]","        if chunk_sentences:","            chunk = ' '.join(chunk_sentences)","            chunks.append(chunk)","        i += sentences_per_chunk - chunk_overlap_sentences","    ","    return chunks","","def token_based_chunk(text, max_tokens=500, overlap_tokens=50):","    \"\"\"","    Split text into chunks based on approximate token count.","    More accurate for embedding models with token limits.","    ","    Args:","        text: Input text","        max_tokens: Maximum tokens per chunk (approx 1 token = 0.75 words)","        overlap_tokens: Overlapping tokens between chunks","        ","    Returns:","        List of text chunks","    \"\"\"","    words = text.split()","    chunks = []","    i = 0","    ","    while i < len(words):","        # Approximate: 1 token â‰ˆ 0.75 words, so adjust accordingly","        chunk_size = int(max_tokens * 0.75)","        chunk_words = words[i:i+chunk_size]","        if chunk_words:","            chunk = ' '.join(chunk_words)","            chunks.append(chunk)","        i += chunk_size - int(overlap_tokens * 0.75)","    ","    return chunks","","def paragraph_chunk_text(text, max_chars=1000, overlap_chars=100):","    \"\"\"","    Split text into chunks by paragraphs with character limits.","    Good for preserving document structure.","    ","    Args:","        text: Input text","        max_chars: Maximum characters per chunk","        overlap_chars: Overlapping characters","        ","    Returns:","        List of text chunks with metadata","    \"\"\"","    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]","    chunks = []","    current_chunk = []","    current_length = 0","    ","    for para in paragraphs:","        para_length = len(para)","        ","        if current_length + para_length > max_chars and current_chunk:","            # Save current chunk","            chunks.append({","                'text': '\\n\\n'.join(current_chunk),","                'char_count': current_length,","                'para_count': len(current_chunk)","            })","            # Start new chunk with overlap","            if overlap_chars > 0 and current_chunk:","                overlap_text = '\\n\\n'.join(current_chunk[-1:])","                current_chunk = [overlap_text[-overlap_chars:]]","                current_length = len(current_chunk[0])","            else:","                current_chunk = []","                current_length = 0","        ","        current_chunk.append(para)","        current_length += para_length + 2  # +2 for \\n\\n","    ","    # Add final chunk","    if current_chunk:","        chunks.append({","            'text': '\\n\\n'.join(current_chunk),","            'char_count': current_length,","            'para_count': len(current_chunk)","        })","    ","    return chunks","","# Demonstrate chunking strategies","if pdf_data:","    print(\"\\n--- Strategy 1: Sentence-Based Chunking ---\")","    sentence_chunks = sentence_chunk_text(","        pdf_data['full_text'], ","        sentences_per_chunk=3, ","        chunk_overlap_sentences=1","    )","    print(f\"Created {len(sentence_chunks)} chunks\")","    print(f\"Sample chunk: {sentence_chunks[0][:150]}...\")","    ","    print(\"\\n--- Strategy 2: Token-Based Chunking ---\")","    token_chunks = token_based_chunk(pdf_data['full_text'], max_tokens=300, overlap_tokens=30)","    print(f\"Created {len(token_chunks)} chunks\")","    print(f\"Sample chunk: {token_chunks[0][:150]}...\")","    ","    print(\"\\n--- Strategy 3: Paragraph-Based Chunking ---\")","    para_chunks = paragraph_chunk_text(pdf_data['full_text'], max_chars=800, overlap_chars=100)","    print(f\"Created {len(para_chunks)} chunks\")","    print(f\"Average chunk size: {sum(c['char_count'] for c in para_chunks)/len(para_chunks):.0f} chars\")","    print(f\"Sample chunk: {para_chunks[0]['text'][:150]}...\")","","# ============================================================================","# PART 6: QDRANT VECTOR DATABASE INTEGRATION","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 6: STORING CHUNKS IN QDRANT\")","print(\"=\"*70)","","def setup_qdrant_collection(collection_name=\"az104_chunks\", vector_size=384):","    \"\"\"","    Initialize Qdrant client and create collection.","    ","    Args:","        collection_name: Name of the collection","        vector_size: Size of embedding vectors (384 for all-MiniLM-L6-v2)","        ","    Returns:","        QdrantClient instance and collection info","    \"\"\"","    try:","        from qdrant_client import QdrantClient, models","        ","        # Initialize Qdrant client (local mode)","        # For production, use: QdrantClient(url=\"https://your-cluster.qdrant.io\", api_key=\"...\")","        client = QdrantClient(location=\":memory:\")  # In-memory for tutorial","        # For persistent storage: QdrantClient(path=\"./qdrant_db\")","        ","        print(f\"âœ“ Connected to Qdrant\")","        ","        # Check if collection exists","        try:","            collection_info = client.get_collection(collection_name)","            print(f\"âœ“ Collection '{collection_name}' already exists\")","            # Optionally delete and recreate for fresh start","            # client.delete_collection(collection_name)","        except:","            # Create new collection","            client.create_collection(","                collection_name=collection_name,","                vectors_config=models.VectorParams(","                    size=vector_size,","                    distance=models.Distance.COSINE  # Cosine similarity","                )","            )","            print(f\"âœ“ Created collection '{collection_name}'\")","        ","        return client, collection_name","        ","    except ImportError:","        print(\"âš  qdrant-client not installed. Install with: pip install qdrant-client\")","        return None, None","    except Exception as e:","        print(f\"âš  Error setting up Qdrant: {e}\")","        return None, None","","def store_chunks_in_qdrant(client, collection_name, chunks, embeddings, metadata=None):","    \"\"\"","    Store text chunks and their embeddings in Qdrant.","    ","    Args:","        client: QdrantClient instance","        collection_name: Name of the collection","        chunks: List of text chunks","        embeddings: List of embedding vectors","        metadata: Optional list of metadata dictionaries","    \"\"\"","    try:","        from qdrant_client import models","        ","        points = []","        for idx, (chunk, embedding) in enumerate(zip(chunks, embeddings)):","            point_metadata = metadata[idx] if metadata and idx < len(metadata) else {}","            point_metadata['text_length'] = len(chunk)","            point_metadata['chunk_id'] = idx","            ","            points.append(","                models.PointStruct(","                    id=str(uuid.uuid4()),","                    vector=embedding.tolist() if hasattr(embedding, 'tolist') else embedding,","                    payload={","                        'text': chunk,","                        **point_metadata","                    }","                )","            )","        ","        # Batch upsert","        client.upsert(","            collection_name=collection_name,","            points=points","        )","        ","        print(f\"âœ“ Stored {len(points)} chunks in Qdrant\")","        return True","        ","    except Exception as e:","        print(f\"âš  Error storing in Qdrant: {e}\")","        return False","","def query_qdrant(client, collection_name, query_text, embedding_model, top_k=5):","    \"\"\"","    Query Qdrant vector database with a text query.","    ","    Args:","        client: QdrantClient instance","        collection_name: Name of the collection","        query_text: Search query text","        embedding_model: SentenceTransformer model for generating embeddings","        top_k: Number of results to return","        ","    Returns:","        List of search results","    \"\"\"","    try:","        # Generate embedding for query","        query_embedding = embedding_model.encode(query_text).tolist()","        ","        # Search in Qdrant","        results = client.search(","            collection_name=collection_name,","            query_vector=query_embedding,","            limit=top_k","        )","        ","        return results","        ","    except Exception as e:","        print(f\"âš  Error querying Qdrant: {e}\")","        return []","","# ============================================================================","# PART 7: COMPLETE WORKFLOW EXAMPLE","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"PART 7: COMPLETE END-TO-END WORKFLOW\")","print(\"=\"*70)","","def complete_workflow_demo():","    \"\"\"","    Complete workflow:","    1. Extract PDF text","    2. Split into indexing/query sets","    3. Chunk the indexing text","    4. Generate embeddings","    5. Store in Qdrant","    6. Query the database","    \"\"\"","    ","    # Check if we have PDF data","    if not pdf_data:","        print(\"âš  No PDF data available. Using sample text.\")","        sample_text = \"\"\"","        Azure Administrator Certification covers managing Azure identities, storage, compute, ","        and networking resources. Key topics include Azure Active Directory, Virtual Machines, ","        Storage Accounts, Virtual Networks, and monitoring solutions.","        \"\"\"","        pdf_data_local = {'full_text': sample_text}","    else:","        pdf_data_local = pdf_data","    ","    try:","        from sentence_transformers import SentenceTransformer","        ","        print(\"\\n--- Step 1: Loading Embedding Model ---\")","        model = SentenceTransformer('all-MiniLM-L6-v2')","        print(f\"âœ“ Loaded model: all-MiniLM-L6-v2 (dimension: {model.get_sentence_embedding_dimension()})\")","        ","        # Step 2: Split data","        print(\"\\n--- Step 2: Splitting Data ---\")","        indexing_text, query_text = split_data_for_vector_db(pdf_data_local['full_text'])","        print(f\"âœ“ Split data: {len(indexing_text)} chars for indexing, {len(query_text)} chars for queries\")","        ","        # Step 3: Chunk indexing text","        print(\"\\n--- Step 3: Chunking Documents ---\")","        chunks = sentence_chunk_text(indexing_text, sentences_per_chunk=3, chunk_overlap_sentences=1)","        print(f\"âœ“ Created {len(chunks)} chunks\")","        ","        # Step 4: Generate embeddings","        print(\"\\n--- Step 4: Generating Embeddings ---\")","        embeddings = model.encode(chunks, show_progress_bar=True)","        print(f\"âœ“ Generated {len(embeddings)} embeddings\")","        ","        # Step 5: Setup Qdrant","        print(\"\\n--- Step 5: Setting up Qdrant ---\")","        client, collection_name = setup_qdrant_collection(","            collection_name=\"az104_chunks\",","            vector_size=model.get_sentence_embedding_dimension()","        )","        ","        if not client:","            print(\"âš  Skipping Qdrant storage due to setup error\")","            return False","        ","        # Step 6: Store in Qdrant","        print(\"\\n--- Step 6: Storing Chunks in Qdrant ---\")","        metadata = [{'source': 'az104_pdf', 'chunk_index': i} for i in range(len(chunks))]","        store_chunks_in_qdrant(client, collection_name, chunks, embeddings, metadata)","        ","        # Step 7: Query examples","        print(\"\\n--- Step 7: Querying Vector Database ---\")","        query_examples = [","            \"What is Azure Active Directory?\",","            \"How do I manage Azure storage?\",","            \"Explain Azure Virtual Machines\",","        ]","        ","        for query in query_examples:","            print(f\"\\nðŸ” Query: '{query}'\")","            results = query_qdrant(client, collection_name, query, model, top_k=3)","            ","            if results:","                print(f\"   Top {len(results)} results:\")","                for i, result in enumerate(results, 1):","                    score = result.score","                    text_preview = result.payload['text'][:150]","                    print(f\"   {i}. [Score: {score:.3f}] {text_preview}...\")","            else:","                print(\"   No results found\")","        ","        print(\"\\n\" + \"=\"*70)","        print(\"âœ“ WORKFLOW COMPLETE!\")","        print(\"=\"*70)","        ","        return True","        ","    except ImportError as e:","        print(f\"\\nâš  Missing dependency: {e}\")","        print(\"Install with: pip install sentence-transformers qdrant-client\")","        return False","    except Exception as e:","        print(f\"\\nâš  Error in workflow: {e}\")","        import traceback","        traceback.print_exc()","        return False","","# Run the complete workflow","complete_workflow_demo()","","# ============================================================================","# PART 8: BEST PRACTICES AND TIPS","# ============================================================================","","print(\"\\n\" + \"=\"*70)","print(\"BEST PRACTICES FOR PDF CHUNKING WITH QDRANT\")","print(\"=\"*70)","","best_practices = \"\"\"","ðŸ“š CHUNKING STRATEGIES FOR PDFS:","","1. SENTENCE-BASED CHUNKING (Recommended for PDFs):","   âœ“ Preserves context and meaning","   âœ“ Better semantic understanding","   âœ“ Ideal for documents with natural language","   âœ“ Use 2-5 sentences per chunk with 1 sentence overlap","","2. PARAGRAPH-BASED CHUNKING:","   âœ“ Maintains document structure","   âœ“ Good for technical documents","   âœ“ Respects natural breaks in content","   âœ“ Use 500-1000 characters per chunk","","3. TOKEN-BASED CHUNKING:","   âœ“ Respects model token limits","   âœ“ Good for embedding models with constraints","   âœ“ More precise size control","   âœ“ Use 256-512 tokens per chunk","","ðŸ”§ QDRANT CONFIGURATION:","","1. DISTANCE METRICS:","   - COSINE: Best for semantic similarity (recommended)","   - EUCLIDEAN: Good for L2 distance","   - DOT: For normalized vectors","","2. VECTOR SIZE:","   - all-MiniLM-L6-v2: 384 dimensions (fast, good quality)","   - all-mpnet-base-v2: 768 dimensions (better quality)","   - BGE models: 768+ dimensions (state-of-the-art)","","3. STORAGE OPTIONS:","   - In-memory: Fast, but data lost on restart","   - Local storage: Persistent, good for development","   - Qdrant Cloud: Production-ready, scalable","","ðŸ“Š DATA SPLITTING:","","1. INDEXING VS QUERY SET:","   - 80-90% for indexing (chunks to search over)","   - 10-20% for queries (test queries)","","2. VALIDATION:","   - Keep test queries separate","   - Don't peek at test set!","   - Use for evaluation metrics","","ðŸŽ¯ OPTIMIZATION TIPS:","","1. CHUNK SIZE:","   - Too small: May lose context","   - Too large: May include irrelevant info","   - Sweet spot: 200-500 tokens","","2. OVERLAP:","   - 10-20% overlap maintains context","   - Prevents information loss at boundaries","   - Improves retrieval quality","","3. METADATA:","   - Store page numbers, sections, source info","   - Enables filtered searches","   - Helps with result interpretation","","4. BATCH PROCESSING:","   - Process chunks in batches","   - Use progress bars for large documents","   - Monitor memory usage","\"\"\"","","print(best_practices)","","print(\"\\n\" + \"=\"*70)","print(\"LESSON COMPLETE! ðŸŽ“\")","print(\"=\"*70)","print(\"\\nNext Steps:\")","print(\"1. Download Azure AZ-104 PDF from Microsoft Learn\")","print(\"2. Install dependencies: pip install -r requirements.txt\")","print(\"3. Run this script: python qdrant_pdf_tutorial.py\")","print(\"4. Experiment with different chunking strategies\")","print(\"5. Build your own Q&A system with the PDF!\")","print(\"\\n\")","",""],"tokenizedAddedLines":[1000000,1000001,1000002,1000003,1000001,1000004,1000005,1000006,1000007,1000008,1000009,1000010,1000004,1000011,1000001,1000000,1000004,1000012,1000013,1000014,1000015,1000004,1000016,1000017,1000016,1000004,1000018,1000019,1000020,1000004,1000021,1000022,1000023,1000004,1000024,1000025,1000026,1000004,1000027,1000028,1000004,1000016,1000029,1000016,1000004,1000018,1000030,1000020,1000004,1000031,1000032,1000033,1000034,1000035,1000036,1000037,1000032,1000038,1000034,1000039,1000040,1000041,1000042,1000043,1000044,1000034,1000045,1000046,1000047,1000034,1000048,1000049,1000050,1000051,1000052,1000034,1000053,1000004,1000054,1000055,1000004,1000016,1000056,1000016,1000004,1000018,1000057,1000020,1000004,1000058,1000032,1000059,1000034,1000060,1000061,1000062,1000063,1000064,1000032,1000065,1000066,1000062,1000067,1000068,1000069,1000070,1000071,1000072,1000073,1000074,1000075,1000076,1000077,1000078,1000073,1000079,1000080,1000081,1000082,1000083,1000073,1000084,1000085,1000086,1000087,1000088,1000073,1000089,1000090,1000091,1000092,1000093,1000094,1000095,1000096,1000097,1000062,1000098,1000099,1000100,1000062,1000101,1000102,1000062,1000103,1000104,1000105,1000106,1000107,1000108,1000109,1000110,1000111,1000112,1000113,1000062,1000114,1000062,1000115,1000062,1000116,1000117,1000118,1000119,1000120,1000062,1000121,1000122,1000123,1000124,1000125,1000123,1000004,1000126,1000127,1000004,1000128,1000129,1000130,1000004,1000016,1000131,1000016,1000004,1000018,1000132,1000020,1000004,1000133,1000032,1000134,1000034,1000060,1000135,1000136,1000062,1000063,1000137,1000032,1000138,1000034,1000139,1000140,1000034,1000141,1000142,1000143,1000144,1000145,1000034,1000146,1000147,1000034,1000148,1000004,1000128,1000149,1000150,1000151,1000152,1000004,1000016,1000153,1000016,1000004,1000018,1000154,1000020,1000004,1000155,1000032,1000156,1000157,1000034,1000060,1000158,1000159,1000160,1000062,1000063,1000161,1000032,1000162,1000163,1000164,1000034,1000165,1000166,1000167,1000168,1000169,1000170,1000171,1000172,1000034,1000173,1000004,1000174,1000032,1000175,1000176,1000034,1000060,1000158,1000177,1000178,1000062,1000063,1000161,1000032,1000179,1000165,1000166,1000034,1000180,1000181,1000182,1000183,1000184,1000185,1000171,1000186,1000034,1000173,1000004,1000187,1000032,1000188,1000189,1000034,1000060,1000158,1000190,1000191,1000062,1000063,1000192,1000032,1000140,1000165,1000193,1000194,1000034,1000195,1000196,1000062,1000197,1000198,1000199,1000200,1000201,1000202,1000110,1000203,1000204,1000205,1000206,1000207,1000208,1000209,1000210,1000062,1000211,1000212,1000034,1000213,1000214,1000215,1000216,1000217,1000218,1000219,1000034,1000173,1000004,1000220,1000128,1000221,1000222,1000223,1000224,1000225,1000145,1000226,1000227,1000034,1000228,1000229,1000230,1000231,1000034,1000232,1000233,1000234,1000235,1000236,1000004,1000016,1000237,1000016,1000004,1000018,1000238,1000020,1000004,1000239,1000032,1000240,1000034,1000060,1000241,1000242,1000062,1000063,1000243,1000032,1000065,1000244,1000062,1000245,1000246,1000247,1000248,1000062,1000249,1000062,1000250,1000251,1000252,1000253,1000254,1000255,1000256,1000257,1000258,1000259,1000260,1000261,1000262,1000263,1000264,1000265,1000062,1000266,1000062,1000121,1000267,1000268,1000124,1000269,1000268,1000004,1000270,1000032,1000271,1000034,1000060,1000272,1000241,1000273,1000274,1000275,1000032,1000065,1000276,1000062,1000277,1000278,1000279,1000280,1000281,1000111,1000282,1000283,1000284,1000285,1000286,1000287,1000288,1000289,1000263,1000264,1000062,1000290,1000291,1000292,1000293,1000294,1000062,1000295,1000296,1000062,1000124,1000297,1000298,1000004,1000299,1000032,1000300,1000034,1000060,1000272,1000241,1000301,1000302,1000303,1000062,1000063,1000304,1000032,1000065,1000305,1000306,1000062,1000307,1000308,1000292,1000309,1000310,1000294,1000062,1000311,1000062,1000124,1000312,1000313,1000004,1000016,1000314,1000016,1000004,1000018,1000315,1000020,1000004,1000316,1000032,1000317,1000318,1000319,1000320,1000321,1000322,1000323,1000032,1000034,1000324,1000325,1000326,1000327,1000328,1000329,1000330,1000331,1000332,1000333,1000334,1000034,1000065,1000335,1000062,1000336,1000337,1000338,1000062,1000339,1000340,1000341,1000342,1000062,1000343,1000344,1000345,1000346,1000062,1000347,1000348,1000349,1000350,1000062,1000351,1000352,1000353,1000354,1000355,1000294,1000062,1000356,1000357,1000358,1000062,1000359,1000360,1000361,1000362,1000062,1000363,1000364,1000365,1000366,1000367,1000368,1000369,1000062,1000370,1000371,1000372,1000111,1000373,1000374,1000375,1000376,1000377,1000378,1000208,1000379,1000062,1000380,1000381,1000382,1000062,1000296,1000062,1000383,1000384,1000385,1000298,1000124,1000386,1000387,1000388,1000298,1000004,1000389,1000390,1000004,1000016,1000391,1000016,1000004,1000018,1000392,1000020,1000004,1000393,1000394,1000004,1000395,1000396,1000397,1000398,1000399,1000004,1000400,1000401,1000402,1000403,1000404,1000004,1000405,1000406,1000407,1000408,1000409,1000004,1000410,1000004,1000411,1000412,1000413,1000414,1000004,1000415,1000416,1000417,1000418,1000004,1000419,1000420,1000421,1000422,1000004,1000423,1000004,1000424,1000425,1000426,1000004,1000427,1000428,1000429,1000430,1000004,1000431,1000004,1000432,1000433,1000434,1000435,1000004,1000436,1000437,1000438,1000439,1000004,1000440,1000441,1000442,1000443,1000004,1000444,1000445,1000446,1000447,1000000,1000004,1000448,1000004,1000018,1000449,1000020,1000450,1000451,1000452,1000453,1000454,1000455,1000456,1000004,1000004]}],"gitInfo":{"noRepoFound":true},"kind":"KIND_ADDED"}